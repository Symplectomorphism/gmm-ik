# Inverse Kinematics via Gaussian Mixture Modeling
Implements expectation maximization to train a Gaussian Mixture Model that
learns the inverse kinematics of a three-link manipulator.

I have compiled a detailed write-up on this problem that can be accessed
[here](./TeX/root.pdf) (if the first page is blank, just click "Download" on the
top right of the page).

* Example usage:
  - ```julia --project=.```
  - ```include("three_link.jl");```
  - ```r = ThreeLink(N=1001, M=61);``` -- Constructs the mechanism and the GMM
    structure.
  - ```execute_em!(r; maxiter=100)``` -- It takes around 20 iterations to
    converge to the specified (hard-coded) tolerance values. The tolerances may
    also be specified using the optional arguments of this function.
  - ```generate_cartesian_distribution(r, nPoints=100)``` -- Generates test
    point and plots the estimation.

### FULL DISCLOSURE: PROOF-OF-CONCEPT CODE -- CAN RUN VERY SLOWLY!


* This is a Julia implementation of the example provided in 
Ghahramani, "Solving Inverse Problems Using an EM Approach To Density Estimation."

* The figures are generated by training a mixture of 101 Gaussian distributions
  over 10001 data points to represent the inverse kinematics.
  
* The figure below depicts a test of the algorithm by the end-effector location
  given by the blue dot.
  - The posterior conditional distribution P(θ | x) is computed using from the
    learned joint probability distribution P(x, θ).
  - P(θ | x) is then sampled to generate the configuration of each link (in
    orange). The end-effector locations that result from this configuration are
    plotted by black stars.
  - The green triangles depict the locations of the revolute joints.
  
![Sample solution](./TeX/figures/sample_solution-v1.png)

* The posterior distribution over θ1 and θ2 given x = [-1.5, -0.4] marginalized
  over θ3 for visualization purposes may be seen below

![Marginal distribution](./TeX/figures/marginal.png)